#!/usr/bin/env python3
"""
é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - ä¸»éƒ¨ç½²è„šæœ¬
ä¸€é”®æ‰§è¡Œå®Œæ•´è®­ç»ƒå’Œæ¨ç†æµç¨‹
"""

# ===========================================
# ç´§æ€¥ä¿®å¤ï¼šdatasetså’Œpyarrowå…¼å®¹æ€§é—®é¢˜
# åœ¨ä»»ä½•å…¶ä»–å¯¼å…¥ä¹‹å‰æ‰§è¡Œ
# ===========================================

print("ğŸ”§ [main] å¼€å§‹ç´§æ€¥ä¿®å¤datasetså…¼å®¹æ€§...")

try:
    # 1. ä¿®å¤pyarrowé—®é¢˜
    import pyarrow as pa
    print(f"ğŸ”§ [main] pyarrowç‰ˆæœ¬: {pa.__version__}")

    if not hasattr(pa, 'PyExtensionType') and hasattr(pa, 'ExtensionType'):
        pa.PyExtensionType = pa.ExtensionType
        print("ğŸ”§ [main] å·²ä¿®å¤pyarrow.PyExtensionType")

    if hasattr(pa, 'lib') and not hasattr(pa.lib, 'PyExtensionType') and hasattr(pa.lib, 'ExtensionType'):
        pa.lib.PyExtensionType = pa.lib.ExtensionType
        print("ğŸ”§ [main] å·²ä¿®å¤pyarrow.lib.PyExtensionType")

except Exception as e:
    print(f"ğŸ”§ [main] pyarrowä¿®å¤å¤±è´¥: {e}")

try:
    # 2. ä¿®å¤datasets LargeListé—®é¢˜
    import datasets
    print(f"ğŸ”§ [main] datasetsç‰ˆæœ¬: {datasets.__version__}")

    if not hasattr(datasets, 'LargeList'):
        print("ğŸ”§ [main] LargeListä¸å­˜åœ¨ï¼Œå¼€å§‹ä¿®å¤...")

        # å°è¯•ä»featureså¯¼å…¥
        try:
            from datasets.features import Sequence
            datasets.LargeList = Sequence
            print("ğŸ”§ [main] å·²ä¿®å¤datasets LargeList (ä½¿ç”¨Sequence)")
        except ImportError as e:
            print(f"ğŸ”§ [main] ä»featureså¯¼å…¥å¤±è´¥: {e}")
            # åˆ›å»ºå®Œæ•´çš„å…¼å®¹ç±»
            class LargeList:
                """Full LargeList compatibility class for datasets"""
                def __init__(self, dtype, length=None):
                    self.dtype = dtype
                    self.length = length

                def __repr__(self):
                    return f"LargeList(dtype={self.dtype}, length={self.length})"

            datasets.LargeList = LargeList
            print("ğŸ”§ [main] å·²åˆ›å»ºdatasets LargeListå…¼å®¹ç±»")

    # éªŒè¯ä¿®å¤
    if hasattr(datasets, 'LargeList'):
        print("âœ… [main] LargeListä¿®å¤æˆåŠŸ")
    else:
        print("âŒ [main] LargeListä¿®å¤å¤±è´¥")

except Exception as e:
    print(f"ğŸ”§ [main] datasetsä¿®å¤å¤±è´¥: {e}")

print("ğŸ”§ [main] ç´§æ€¥ä¿®å¤å®Œæˆï¼Œå¼€å§‹æ­£å¸¸å¯¼å…¥...\n")

# ===========================================
# æ­£å¸¸å¯¼å…¥å¼€å§‹
# ===========================================

import os
import sys
import argparse
import subprocess
from pathlib import Path

# åœ¨å¯¼å…¥å¯èƒ½ä¾èµ–datasetsçš„åº“ä¹‹å‰ï¼Œå…ˆä¿®å¤datasetså…¼å®¹æ€§é—®é¢˜
def fix_datasets_import():
    """ä¿®å¤datasetså¯¼å…¥é—®é¢˜"""
    try:
        import datasets
        if not hasattr(datasets, 'LargeList'):
            # å°è¯•ä»featureså¯¼å…¥
            try:
                from datasets.features import Sequence
                datasets.LargeList = Sequence
                print("ğŸ”§ å·²è‡ªåŠ¨ä¿®å¤datasets LargeListå¯¼å…¥é—®é¢˜")
            except ImportError:
                # åˆ›å»ºåŸºç¡€å…¼å®¹ç±»
                class LargeList:
                    pass
                datasets.LargeList = LargeList
                print("ğŸ”§ å·²åˆ›å»ºdatasets LargeListå…¼å®¹ç±»")
    except ImportError:
        pass

# è¿è¡Œä¿®å¤
fix_datasets_import()

def show_recovery_options(failed_step):
    """æ˜¾ç¤ºé”™è¯¯æ¢å¤é€‰é¡¹"""
    print("\n" + "="*60)
    print(f"ğŸ”§ {failed_step} å¤±è´¥ - æ¢å¤é€‰é¡¹")
    print("="*60)

    steps = {
        'analysis': ['æ•°æ®ä¸‹è½½é—®é¢˜', 'python scripts/data_processor.py download', 'python scripts/data_processor.py analyze'],
        'train': ['ä¾èµ–æˆ–æ¨¡å‹é—®é¢˜', 'python fix_datasets_compatibility.py', 'python main.py --step train'],
        'inference': ['æ¨¡å‹æ–‡ä»¶é—®é¢˜', 'ls -la models/', 'python main.py --step inference'],
        'evaluate': ['ç»“æœæ–‡ä»¶é—®é¢˜', 'ls -la results/', 'python main.py --step evaluate']
    }

    if failed_step in steps:
        issue, check_cmd, retry_cmd = steps[failed_step]
        print(f"å¯èƒ½é—®é¢˜: {issue}")
        print(f"æ£€æŸ¥å‘½ä»¤: {check_cmd}")
        print(f"é‡è¯•å‘½ä»¤: {retry_cmd}")

    print("\né€šç”¨è§£å†³æ–¹æ³•:")
    print("1. ğŸ“¦ æ£€æŸ¥ä¾èµ–: python test_setup.py")
    print("2. ğŸ”§ ä¿®å¤PyArrow: python fix_pyarrow_manual.py")
    print("3. ğŸ“Š ä¿®å¤datasets: python fix_datasets_compatibility.py")
    print("4. ğŸ“ æŸ¥çœ‹æ—¥å¿—: tail -f logs/train.log")
    print("5. â­ï¸  è·³è¿‡æ­¤æ­¥éª¤: python main.py --step all --skip-step " + failed_step)
    print("="*60)

def show_command_error(cmd, error):
    """æ˜¾ç¤ºå‘½ä»¤æ‰§è¡Œé”™è¯¯è¯¦æƒ…"""
    print("\n" + "="*60)
    print("ğŸ” é”™è¯¯è¯¦æƒ…")
    print("="*60)
    print(f"å‘½ä»¤: {cmd}")
    print(f"é€€å‡ºç : {error.returncode}")

    if error.stdout and error.stdout.strip():
        print(f"\nğŸ“ æ ‡å‡†è¾“å‡º:")
        # åªæ˜¾ç¤ºæœ€åå‡ è¡Œï¼Œé¿å…è¾“å‡ºå¤ªé•¿
        stdout_lines = error.stdout.strip().split('\n')
        if len(stdout_lines) > 20:
            print("... (è¾“å‡ºè¿‡é•¿ï¼Œåªæ˜¾ç¤ºæœ€å20è¡Œ)")
            stdout_lines = stdout_lines[-20:]
        for line in stdout_lines:
            print(f"  {line}")

    if error.stderr and error.stderr.strip():
        print(f"\nâŒ é”™è¯¯è¾“å‡º:")
        # åªæ˜¾ç¤ºæœ€åå‡ è¡Œé”™è¯¯ä¿¡æ¯
        stderr_lines = error.stderr.strip().split('\n')
        if len(stderr_lines) > 20:
            print("... (é”™è¯¯è¾“å‡ºè¿‡é•¿ï¼Œåªæ˜¾ç¤ºæœ€å20è¡Œ)")
            stderr_lines = stderr_lines[-20:]
        for line in stderr_lines:
            print(f"  {line}")

    print("="*60)
    print("ğŸ’¡ è§£å†³å»ºè®®:")
    print("1. æ£€æŸ¥ä¾èµ–: python test_setup.py")
    print("2. ä¿®å¤PyArrow: python fix_pyarrow_manual.py")
    print("3. ä¿®å¤datasets: python fix_datasets_compatibility.py")
    print("4. æŸ¥çœ‹æ—¥å¿—: tail -f logs/train.log")
    print("="*60)

def run_command(cmd, desc=""):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºçŠ¶æ€"""
    print(f"ğŸ”§ {desc}")
    try:
        # æ£€æµ‹è¿è¡Œç¯å¢ƒ
        if os.path.exists('/mnt/workspace'):
            # é­”æ­å¹³å°ç¯å¢ƒ - ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºå·¥ä½œç›®å½•ï¼Œå¹¶ç¡®ä¿site_packagesåœ¨PYTHONPATHä¸­
            env = os.environ.copy()
            current_dir = os.getcwd()
            site_packages_path = os.path.join(current_dir, 'site_packages')
            existing_pythonpath = env.get('PYTHONPATH', '')
            if existing_pythonpath:
                env['PYTHONPATH'] = f"{site_packages_path}:{current_dir}:{existing_pythonpath}"
            else:
                env['PYTHONPATH'] = f"{site_packages_path}:{current_dir}"
            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True, env=env, cwd=current_dir)
        else:
            # æœ¬åœ°ç¯å¢ƒ
            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        print("âœ… æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ å¤±è´¥")
        show_command_error(cmd, e)
        return False

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒ...")

    # æ£€æµ‹è¿è¡Œç¯å¢ƒ
    in_modelscope = os.path.exists('/mnt/workspace')
    print(f"  è¿è¡Œç¯å¢ƒ: {'é­”æ­å¹³å°' if in_modelscope else 'æœ¬åœ°ç¯å¢ƒ'}")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"  Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")

    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    required_modules = ['torch']
    recommended_modules = ['transformers', 'datasets']
    missing_required = []
    missing_recommended = []

    for module in required_modules:
        try:
            __import__(module)
            print(f"  âœ… {module}")
        except ImportError:
            print(f"  âŒ {module} (å¿…éœ€)")
            missing_required.append(module)

    for module in recommended_modules:
        try:
            __import__(module)
            print(f"  âœ… {module}")
        except ImportError as e:
            error_msg = str(e)[:50]
            if "PyExtensionType" in error_msg:
                error_msg = "ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·è¿è¡Œ: python fix_modelscope_deps.py"
            print(f"  âš ï¸  {module} (æ¨è) - {error_msg}")
            missing_recommended.append(module)

    if missing_required:
        print(f"\nâŒ ç¼ºå°‘å¿…éœ€ä¾èµ–åŒ…: {', '.join(missing_required)}")
        if in_modelscope:
            print("è¯·åœ¨é­”æ­å¹³å°è¿è¡Œ: python fix_modelscope_deps.py")
        else:
            print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False

    if missing_recommended:
        print(f"\nâš ï¸  ç¼ºå°‘æ¨èä¾èµ–åŒ…: {', '.join(missing_recommended)}")
        print("æŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        if in_modelscope:
            print("å»ºè®®è¿è¡Œ: python fix_modelscope_deps.py")

    # æ£€æŸ¥GPU
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        gpu_count = torch.cuda.device_count() if gpu_available else 0
        print(f"  GPU: {'âœ… å¯ç”¨' if gpu_available else 'âŒ ä¸å¯ç”¨'} ({gpu_count}ä¸ª)")
    except:
        print("  GPU: æ£€æŸ¥å¤±è´¥")

    return True

def run_data_analysis():
    """è¿è¡Œæ•°æ®åˆ†æ"""
    print("\n" + "="*60)
    print("ğŸ“Š ç¬¬ä¸€æ­¥: æ•°æ®é›†å¤„ç†")
    print("="*60)

    script_path = "scripts/data_processor.py"
    if os.path.exists(script_path):
        # å…ˆä¸‹è½½æ•°æ®
        success = run_command(f"python {script_path} download", "ä¸‹è½½æ•°æ®é›†")
        if success:
            # å†åˆ†ææ•°æ®
            return run_command(f"python {script_path} analyze", "åˆ†ææ•°æ®é›†")
        return False
    else:
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®å¤„ç†è„šæœ¬")
        return False

def run_training():
    """è¿è¡Œæ¨¡å‹è®­ç»ƒ"""
    print("\n" + "="*60)
    print("ğŸš€ ç¬¬äºŒæ­¥: æ¨¡å‹è®­ç»ƒ")
    print("="*60)

    script_path = "scripts/model_trainer.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path} train", "è®­ç»ƒæ¨¡å‹")
    else:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹è®­ç»ƒè„šæœ¬")
        return False

def run_inference():
    """è¿è¡Œæ¨¡å‹æ¨ç†"""
    print("\n" + "="*60)
    print("ğŸ§  ç¬¬ä¸‰æ­¥: æ¨¡å‹æ¨ç†")
    print("="*60)

    script_path = "scripts/model_trainer.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path} inference", "è¿è¡Œæ¨ç†")
    else:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ¨ç†è„šæœ¬")
        return False

def run_evaluation():
    """è¿è¡Œæ€§èƒ½è¯„ä¼°"""
    print("\n" + "="*60)
    print("ğŸ“Š ç¬¬å››æ­¥: æ€§èƒ½è¯„ä¼°")
    print("="*60)

    script_path = "scripts/evaluate.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path}", "è¯„ä¼°æ€§èƒ½")
    else:
        print("âŒ æ‰¾ä¸åˆ°è¯„ä¼°è„šæœ¬")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - éƒ¨ç½²å·¥å…·")
    parser.add_argument('--step', choices=['all', 'analysis', 'train', 'inference', 'evaluate'],
                       default='all', help='æ‰§è¡Œç‰¹å®šæ­¥éª¤ (é»˜è®¤: all)')
    parser.add_argument('--skip-env-check', action='store_true',
                       help='è·³è¿‡ç¯å¢ƒæ£€æŸ¥')

    args = parser.parse_args()

    print("ğŸ° é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - éƒ¨ç½²å·¥å…·")
    print("=" * 60)

    # æ£€æŸ¥ç¯å¢ƒ
    if not args.skip_env_check:
        if not check_environment():
            print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤ä¾èµ–é—®é¢˜åé‡è¯•")
            return

    # æ‰§è¡Œç›¸åº”æ­¥éª¤ - é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œæ­¥éª¤: {args.step}")
    print("-" * 60)

    try:
        if args.step in ['all', 'analysis']:
            print("\nğŸ“Š æ‰§è¡Œ: æ•°æ®åˆ†æ")
            if not run_data_analysis():
                print("\nâŒ æ•°æ®åˆ†æå¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                show_recovery_options("analysis")
                return

        if args.step in ['all', 'train']:
            print("\nğŸš€ æ‰§è¡Œ: æ¨¡å‹è®­ç»ƒ")
            if not run_training():
                print("\nâŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                show_recovery_options("train")
                return

        if args.step in ['all', 'inference']:
            print("\nğŸ§  æ‰§è¡Œ: æ¨¡å‹æ¨ç†")
            if not run_inference():
                print("\nâŒ æ¨¡å‹æ¨ç†å¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                show_recovery_options("inference")
                return

        if args.step in ['all', 'evaluate']:
            print("\nğŸ“Š æ‰§è¡Œ: æ€§èƒ½è¯„ä¼°")
            if not run_evaluation():
                print("\nâŒ æ€§èƒ½è¯„ä¼°å¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                show_recovery_options("evaluate")
                return

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥é”™è¯¯è¯¦æƒ…å¹¶ä¿®å¤é—®é¢˜ã€‚")
        return

    # æ€»ç»“
    print("\n" + "="*60)
    if success:
        print("ğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
        print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print("  â€¢ æ¨¡å‹: models/ ç›®å½•")
        print("  â€¢ ç»“æœ: results/ ç›®å½•")
        print("  â€¢ æ—¥å¿—: logs/ ç›®å½•")

        print("\nğŸ† ç«èµ›æäº¤:")
        print("  1. å¤åˆ¶ç»“æœæ–‡ä»¶: cp results/enhanced_result.jsonl results/result.json")
        print("  2. æäº¤ result.json åˆ°ç«èµ›é¡µé¢")
    else:
        print("âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    print("="*60)

if __name__ == '__main__':
    main()
