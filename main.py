#!/usr/bin/env python3
"""
é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - ä¸»éƒ¨ç½²è„šæœ¬
ä¸€é”®æ‰§è¡Œå®Œæ•´è®­ç»ƒå’Œæ¨ç†æµç¨‹
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path

def run_command(cmd, desc=""):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºçŠ¶æ€"""
    print(f"ğŸ”§ {desc}")
    try:
        # æ£€æµ‹è¿è¡Œç¯å¢ƒ
        if os.path.exists('/mnt/workspace'):
            # é­”æ­å¹³å°ç¯å¢ƒ - ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºå·¥ä½œç›®å½•
            env = os.environ.copy()
            current_dir = os.getcwd()
            env['PYTHONPATH'] = current_dir
            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True, env=env, cwd=current_dir)
        else:
            # æœ¬åœ°ç¯å¢ƒ
            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        print("âœ… æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ å¤±è´¥: {e.stderr}")
        return False

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒ...")

    # æ£€æµ‹è¿è¡Œç¯å¢ƒ
    in_modelscope = os.path.exists('/mnt/workspace')
    print(f"  è¿è¡Œç¯å¢ƒ: {'é­”æ­å¹³å°' if in_modelscope else 'æœ¬åœ°ç¯å¢ƒ'}")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"  Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")

    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    required_modules = ['torch']
    recommended_modules = ['transformers', 'datasets']
    missing_required = []
    missing_recommended = []

    for module in required_modules:
        try:
            __import__(module)
            print(f"  âœ… {module}")
        except ImportError:
            print(f"  âŒ {module} (å¿…éœ€)")
            missing_required.append(module)

    for module in recommended_modules:
        try:
            __import__(module)
            print(f"  âœ… {module}")
        except ImportError as e:
            error_msg = str(e)[:50]
            if "PyExtensionType" in error_msg:
                error_msg = "ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·è¿è¡Œ: python fix_modelscope_deps.py"
            print(f"  âš ï¸  {module} (æ¨è) - {error_msg}")
            missing_recommended.append(module)

    if missing_required:
        print(f"\nâŒ ç¼ºå°‘å¿…éœ€ä¾èµ–åŒ…: {', '.join(missing_required)}")
        if in_modelscope:
            print("è¯·åœ¨é­”æ­å¹³å°è¿è¡Œ: python fix_modelscope_deps.py")
        else:
            print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False

    if missing_recommended:
        print(f"\nâš ï¸  ç¼ºå°‘æ¨èä¾èµ–åŒ…: {', '.join(missing_recommended)}")
        print("æŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        if in_modelscope:
            print("å»ºè®®è¿è¡Œ: python fix_modelscope_deps.py")

    # æ£€æŸ¥GPU
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        gpu_count = torch.cuda.device_count() if gpu_available else 0
        print(f"  GPU: {'âœ… å¯ç”¨' if gpu_available else 'âŒ ä¸å¯ç”¨'} ({gpu_count}ä¸ª)")
    except:
        print("  GPU: æ£€æŸ¥å¤±è´¥")

    return True

def run_data_analysis():
    """è¿è¡Œæ•°æ®åˆ†æ"""
    print("\n" + "="*60)
    print("ğŸ“Š ç¬¬ä¸€æ­¥: æ•°æ®é›†å¤„ç†")
    print("="*60)

    script_path = "scripts/data_processor.py"
    if os.path.exists(script_path):
        # å…ˆä¸‹è½½æ•°æ®
        success = run_command(f"python {script_path} download", "ä¸‹è½½æ•°æ®é›†")
        if success:
            # å†åˆ†ææ•°æ®
            return run_command(f"python {script_path} analyze", "åˆ†ææ•°æ®é›†")
        return False
    else:
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®å¤„ç†è„šæœ¬")
        return False

def run_training():
    """è¿è¡Œæ¨¡å‹è®­ç»ƒ"""
    print("\n" + "="*60)
    print("ğŸš€ ç¬¬äºŒæ­¥: æ¨¡å‹è®­ç»ƒ")
    print("="*60)

    script_path = "scripts/model_trainer.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path} train", "è®­ç»ƒæ¨¡å‹")
    else:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹è®­ç»ƒè„šæœ¬")
        return False

def run_inference():
    """è¿è¡Œæ¨¡å‹æ¨ç†"""
    print("\n" + "="*60)
    print("ğŸ§  ç¬¬ä¸‰æ­¥: æ¨¡å‹æ¨ç†")
    print("="*60)

    script_path = "scripts/model_trainer.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path} inference", "è¿è¡Œæ¨ç†")
    else:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ¨ç†è„šæœ¬")
        return False

def run_evaluation():
    """è¿è¡Œæ€§èƒ½è¯„ä¼°"""
    print("\n" + "="*60)
    print("ğŸ“Š ç¬¬å››æ­¥: æ€§èƒ½è¯„ä¼°")
    print("="*60)

    script_path = "scripts/evaluate.py"
    if os.path.exists(script_path):
        return run_command(f"python {script_path}", "è¯„ä¼°æ€§èƒ½")
    else:
        print("âŒ æ‰¾ä¸åˆ°è¯„ä¼°è„šæœ¬")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - éƒ¨ç½²å·¥å…·")
    parser.add_argument('--step', choices=['all', 'analysis', 'train', 'inference', 'evaluate'],
                       default='all', help='æ‰§è¡Œç‰¹å®šæ­¥éª¤ (é»˜è®¤: all)')
    parser.add_argument('--skip-env-check', action='store_true',
                       help='è·³è¿‡ç¯å¢ƒæ£€æŸ¥')

    args = parser.parse_args()

    print("ğŸ° é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - éƒ¨ç½²å·¥å…·")
    print("=" * 60)

    # æ£€æŸ¥ç¯å¢ƒ
    if not args.skip_env_check:
        if not check_environment():
            print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤ä¾èµ–é—®é¢˜åé‡è¯•")
            return

    # æ‰§è¡Œç›¸åº”æ­¥éª¤ - é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œæ­¥éª¤: {args.step}")
    print("-" * 60)

    try:
        if args.step in ['all', 'analysis']:
            print("\nğŸ“Š æ‰§è¡Œ: æ•°æ®åˆ†æ")
            if not run_data_analysis():
                print("\nâŒ æ•°æ®åˆ†æå¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
                return

        if args.step in ['all', 'train']:
            print("\nğŸš€ æ‰§è¡Œ: æ¨¡å‹è®­ç»ƒ")
            if not run_training():
                print("\nâŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
                return

        if args.step in ['all', 'inference']:
            print("\nğŸ§  æ‰§è¡Œ: æ¨¡å‹æ¨ç†")
            if not run_inference():
                print("\nâŒ æ¨¡å‹æ¨ç†å¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
                return

        if args.step in ['all', 'evaluate']:
            print("\nğŸ“Š æ‰§è¡Œ: æ€§èƒ½è¯„ä¼°")
            if not run_evaluation():
                print("\nâŒ æ€§èƒ½è¯„ä¼°å¤±è´¥ï¼åœæ­¢æ‰§è¡Œã€‚")
                print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
                return

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥é”™è¯¯è¯¦æƒ…å¹¶ä¿®å¤é—®é¢˜ã€‚")
        return

    # æ€»ç»“
    print("\n" + "="*60)
    if success:
        print("ğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
        print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print("  â€¢ æ¨¡å‹: models/ ç›®å½•")
        print("  â€¢ ç»“æœ: results/ ç›®å½•")
        print("  â€¢ æ—¥å¿—: logs/ ç›®å½•")

        print("\nğŸ† ç«èµ›æäº¤:")
        print("  1. å¤åˆ¶ç»“æœæ–‡ä»¶: cp results/enhanced_result.jsonl results/result.json")
        print("  2. æäº¤ result.json åˆ°ç«èµ›é¡µé¢")
    else:
        print("âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    print("="*60)

if __name__ == '__main__':
    main()
