#!/usr/bin/env python3
"""
é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - æ¨¡å‹è®­ç»ƒå’Œæ¨ç†è„šæœ¬
åˆå¹¶è®­ç»ƒå’Œæ¨ç†åŠŸèƒ½
"""

import os
import re
import json
import torch
import argparse
from typing import Dict, Any, List, Optional
from swift.llm import (
    TrainArguments, sft_main, register_dataset, DatasetMeta, ResponsePreprocessor, SubsetDataset,
    InferArguments, infer_main
)
from swift.utils import read_from_jsonl, write_to_jsonl
from pathlib import Path

os.environ['CUDA_VISIBLE_DEVICES'] = '0'

def get_project_root():
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    # ä»å½“å‰è„šæœ¬ä½ç½®å‘ä¸Šä¸¤çº§åˆ°è¾¾é¡¹ç›®æ ¹ç›®å½•
    current_file = Path(__file__).resolve()
    return current_file.parent.parent

class EnhancedPreprocessor(ResponsePreprocessor):
    """ä¼˜åŒ–çš„æ•°æ®é¢„å¤„ç†å™¨"""

    def preprocess(self, row: Dict[str, Any]) -> Dict[str, Any]:
        query = f"""åˆ¤æ–­ä¸‹é¢ä¸¤å¥é‡‘èå’¨è¯¢æ–‡æœ¬æ˜¯å¦è¡¨è¾¾ç›¸åŒçš„è¯­ä¹‰å«ä¹‰ã€‚

å¥å­1: {row['text1']}
å¥å­2: {row['text2']}

è§„åˆ™ï¼š
- å«ä¹‰ç›¸åŒæˆ–éå¸¸ç›¸ä¼¼: è¾“å‡º1
- å«ä¹‰ä¸åŒæˆ–ä¸ç›¸ä¼¼: è¾“å‡º0
- åªè¾“å‡ºå•ä¸ªæ•°å­—0æˆ–1

ç»“æœ: """

        response = str(row['label'])
        row = {
            'query': query,
            'response': response
        }
        return super().preprocess(row)

def register_datasets():
    """æ³¨å†Œæ•°æ®é›†"""
    register_dataset(
        DatasetMeta(
            ms_dataset_id='swift/financial_classification',
            subsets=[
                SubsetDataset('train', split=['train']),
                SubsetDataset('val', split=['train[:1000]']),  # ä½¿ç”¨å‰1000ä¸ªæ ·æœ¬ä½œä¸ºéªŒè¯é›†
                SubsetDataset('test', split=['test'])
            ],
            preprocess_func=EnhancedPreprocessor(),
            dataset_config={
                'trust_remote_code': True,
                'download_mode': 'reuse_dataset_if_exists'
            }
        )
    )

def load_config():
    """åŠ è½½è®­ç»ƒé…ç½®"""
    import json
    project_root = get_project_root()
    config_file = project_root / 'config' / 'train_config.json'

    with open(config_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_training_args(output_dir: Optional[str] = None) -> TrainArguments:
    """è·å–ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°"""
    if output_dir is None:
        project_root = get_project_root()
        output_dir = str(project_root / 'models' / 'enhanced_output')

    # åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config()

    return TrainArguments(
        model=config['model']['model_id'],
        model_type=config['model']['model_type'],
        dataset=['swift/financial_classification:train'],
        dataset_config={
            'trust_remote_code': True,
            'download_mode': 'reuse_dataset_if_exists'
        },
        # ç±»åˆ«å¹³è¡¡è°ƒæ•´ï¼ˆè®­ç»ƒé›†ä¸­0:69%, 1:31%ï¼‰
        loss_scale_config={
            '0': 0.7,  # å‡å°‘å¤šæ•°ç±»æƒé‡
            '1': 1.3   # å¢åŠ å°‘æ•°ç±»æƒé‡
        },
        train_type='lora',
        torch_dtype=config['model']['torch_dtype'],
        output_dir=output_dir,
        num_train_epochs=config['training']['num_train_epochs'],
        per_device_train_batch_size=config['training']['per_device_train_batch_size'],
        per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],
        gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],
        learning_rate=config['training']['learning_rate'],
        lr_scheduler_type='cosine',
        warmup_ratio=config['training']['warmup_ratio'],
        weight_decay=config['training']['weight_decay'],
        max_grad_norm=config['training']['max_grad_norm'],
        max_length=config['training']['max_length'],
        gradient_checkpointing=config['training']['gradient_checkpointing'],
        optim=config['training']['optim'],
        dataloader_num_workers=config['training']['dataloader_num_workers'],
        dataloader_pin_memory=config['training']['dataloader_pin_memory'],
        # æ˜¾å­˜ä¼˜åŒ–è®¾ç½®
        packing=True,
        dataset_num_proc=1,  # å‡å°‘è¿›ç¨‹æ•°èŠ‚çœæ˜¾å­˜
        ddp_find_unused_parameters=False,
        # é¢å¤–æ˜¾å­˜ä¼˜åŒ–
        use_flash_attn=True,  # å¯ç”¨flash attention
        model_kwargs={
            "trust_remote_code": True,
            "torch_dtype": "bfloat16",
            "use_cache": False  # è®­ç»ƒæ—¶å…³é—­KV cacheèŠ‚çœæ˜¾å­˜
        },
        save_steps=config['training']['save_steps'],
        eval_steps=config['training']['eval_steps'],
        logging_steps=config['training']['logging_steps'],
        save_total_limit=config['training']['save_total_limit'],
        load_best_model_at_end=config['training']['load_best_model_at_end'],
        metric_for_best_model=config['training']['metric_for_best_model'],
        greater_is_better=config['training']['greater_is_better'],
        lora_rank=config['lora']['lora_rank'],
        lora_alpha=config['lora']['lora_alpha'],
        lora_dropout=config['lora']['lora_dropout'],
        target_modules=config['lora']['target_modules'],
        max_grad_norm=1.0,
        save_only_model=True,
        packing=True,
        dataset_num_proc=4,
        dataloader_num_workers=4,
        attn_impl='flash_attn',
        use_nested_quant=True,
        system="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ¤æ–­ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä¸¤å¥è¯åœ¨é‡‘èè¯­å¢ƒä¸‹çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œåªè¾“å‡º0æˆ–1ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚",
        seed=42,
        gradient_checkpointing=True,
        ddp_find_unused_parameters=False,
        early_stopping=True,
        early_stopping_patience=3,
        early_stopping_threshold=0.001,
    )

def extract_prediction(response: str) -> int:
    """ä»æ¨¡å‹è¾“å‡ºä¸­æå–é¢„æµ‹ç»“æœ"""
    if not response:
        return 0

    response = response.strip()

    # ç›´æ¥åŒ¹é…æ•°å­—0æˆ–1
    if response in ['0', '1']:
        return int(response)

    # åŒ¹é…åŒ…å«æ•°å­—çš„æ¨¡å¼
    digit_match = re.search(r'\b([01])\b', response)
    if digit_match:
        return int(digit_match.group(1))

    # åŸºäºå…³é”®è¯åˆ¤æ–­
    response_lower = response.lower()
    positive_keywords = ['ç›¸ä¼¼', 'ç›¸åŒ', 'ç±»ä¼¼', 'ä¸€è‡´', 'æ˜¯', 'yes', 'true']
    negative_keywords = ['ä¸åŒ', 'ä¸ç›¸ä¼¼', 'ä¸ç›¸åŒ', 'å·®å¼‚', 'ä¸æ˜¯', 'no', 'false']

    positive_score = sum(1 for word in positive_keywords if word in response_lower)
    negative_score = sum(1 for word in negative_keywords if word in response_lower)

    if positive_score > negative_score:
        return 1
    elif negative_score > positive_score:
        return 0
    else:
        return 0

def find_best_checkpoint(output_dir: Optional[str] = None) -> Optional[str]:
    """æŸ¥æ‰¾æœ€ä½³checkpoint"""
    if output_dir is None:
        project_root = get_project_root()
        output_dir = str(project_root / 'models' / 'enhanced_output')
    """æŸ¥æ‰¾æœ€ä½³checkpoint"""
    import glob

    checkpoint_pattern = f"{output_dir}/checkpoint-*"
    checkpoint_dirs = glob.glob(checkpoint_pattern)

    if not checkpoint_dirs:
        print(f"âŒ æœªæ‰¾åˆ°checkpointæ–‡ä»¶: {checkpoint_pattern}")
        return None

    try:
        latest_checkpoint = max(checkpoint_dirs, key=lambda x: int(x.split('-')[-1]))
        print(f"âœ… æ‰¾åˆ°æœ€ä½³æ¨¡å‹: {latest_checkpoint}")
        return latest_checkpoint
    except ValueError:
        print(f"âš ï¸ æ— æ³•ç¡®å®šæœ€ä½³checkpointï¼Œä½¿ç”¨: {checkpoint_dirs[0]}")
        return checkpoint_dirs[0]

def get_inference_args(ckpt_dir: str) -> InferArguments:
    """è·å–æ¨ç†å‚æ•°"""
    project_root = get_project_root()
    result_path = str(project_root / 'results' / 'enhanced_result.jsonl')

    # åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config()

    return InferArguments(
        adapters=[ckpt_dir],
        temperature=config['inference']['temperature'],
        max_batch_size=16,
        max_new_tokens=config['inference']['max_new_tokens'],
        val_dataset=["swift/financial_classification:test"],
        infer_backend='pt',
        do_sample=config['inference']['do_sample'],
        repetition_penalty=config['inference']['repetition_penalty'],
        result_path=result_path
    )

def run_training():
    """è¿è¡Œæ¨¡å‹è®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)

    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ… GPUå¯ç”¨: {gpu_count} Ã— {gpu_name}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        return False

    # æ³¨å†Œæ•°æ®é›†
    print("\nğŸ“ æ³¨å†Œæ•°æ®é›†...")
    try:
        register_datasets()
        print("âœ… æ•°æ®é›†æ³¨å†ŒæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ³¨å†Œå¤±è´¥: {e}")
        return False

    # è·å–è®­ç»ƒå‚æ•°
    train_args = get_training_args()
    print("\nğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"  â€¢ æ¨¡å‹: {train_args.model}")
    print(f"  â€¢ è®­ç»ƒè½®æ•°: {train_args.num_train_epochs}")
    print(f"  â€¢ å­¦ä¹ ç‡: {train_args.learning_rate}")
    print(f"  â€¢ LoRA rank: {train_args.lora_rank}")
    print(f"  â€¢ è¾“å‡ºç›®å½•: {train_args.output_dir}")

    # å¼€å§‹è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("ğŸ’¡ æç¤º: è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    try:
        sft_main(train_args)
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        return True
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        print("\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print("=" * 50)
        import traceback
        traceback.print_exc()
        print("=" * 50)

        print("\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ³•:")
        print("1. æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨: python -c 'import torch; print(torch.cuda.is_available())'")
        print("2. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³")
        print("3. æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("4. å°è¯•ä½¿ç”¨æ›´å°çš„batch_size")
        print("5. æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…: python test_setup.py")

        return False

def run_inference():
    """è¿è¡Œæ¨¡å‹æ¨ç†"""
    print("ğŸ§  å¼€å§‹æ¨¡å‹æ¨ç†")
    print("=" * 50)

    # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
    print("\nğŸ“ æŸ¥æ‰¾æœ€ä½³æ¨¡å‹...")
    ckpt_dir = find_best_checkpoint()
    if not ckpt_dir:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹checkpoint")
        return False

    # æ³¨å†Œæ•°æ®é›†
    print("\nğŸ“ æ³¨å†Œæ¨ç†æ•°æ®é›†...")
    try:
        register_datasets()
        print("âœ… æ•°æ®é›†æ³¨å†ŒæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ³¨å†Œå¤±è´¥: {e}")
        return False

    # è·å–æ¨ç†å‚æ•°
    infer_args = get_inference_args(ckpt_dir)

    print("ğŸ“‹ æ¨ç†é…ç½®:")
    print(f"  â€¢ æ¨¡å‹: {ckpt_dir}")
    print(f"  â€¢ æ¸©åº¦: {infer_args.temperature}")
    print(f"  â€¢ æ‰¹æ¬¡å¤§å°: {infer_args.max_batch_size}")
    print(f"  â€¢ è¾“å‡ºæ–‡ä»¶: {infer_args.result_path}")

    # å¼€å§‹æ¨ç†
    print("\nğŸ§  å¼€å§‹æ¨ç†...")
    try:
        result = infer_main(infer_args)
        print("âœ… æ¨ç†å®Œæˆï¼")
        return True
    except Exception as e:
        print(f"\nâŒ æ¨ç†å¤±è´¥: {e}")
        print("\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print("=" * 50)
        import traceback
        traceback.print_exc()
        print("=" * 50)

        print("\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ³•:")
        print("1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("2. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³")
        print("3. æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æ­£ç¡®æ³¨å†Œ")
        print("4. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ç¡®è®¤æ¨¡å‹è®­ç»ƒæ˜¯å¦æ­£å¸¸å®Œæˆ")

        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¨¡å‹è®­ç»ƒå’Œæ¨ç†è„šæœ¬")
    parser.add_argument('action', choices=['train', 'inference', 'all'],
                       help='æ‰§è¡Œæ“ä½œ: train(è®­ç»ƒ), inference(æ¨ç†), all(è®­ç»ƒ+æ¨ç†)')

    args = parser.parse_args()

    success = True

    if args.action in ['train', 'all']:
        success &= run_training()

    if args.action in ['inference', 'all']:
        success &= run_inference()

    if success:
        print("\nğŸ‰ æ“ä½œå®Œæˆï¼")
        if args.action in ['inference', 'all']:
            print("\nğŸ“¤ ç»“æœæ–‡ä»¶:")
            print("  â€¢ æ¨ç†ç»“æœ: results/enhanced_result.jsonl")
            print("  â€¢ ç«èµ›æäº¤: cp results/enhanced_result.jsonl results/result.json")
    else:
        print("\nâŒ æ“ä½œå¤±è´¥")

if __name__ == '__main__':
    main()
