"""
é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - è„šæœ¬åŒ…
"""

# åœ¨å¯¼å…¥ä»»ä½•å¯èƒ½ä¾èµ–datasetsçš„åº“ä¹‹å‰ï¼Œå…ˆä¿®å¤datasetså…¼å®¹æ€§é—®é¢˜
def fix_datasets_import():
    """ä¿®å¤datasetså¯¼å…¥é—®é¢˜"""
    try:
        import datasets
        if not hasattr(datasets, 'LargeList'):
            # å°è¯•ä»featureså¯¼å…¥
            try:
                from datasets.features import Sequence
                datasets.LargeList = Sequence
                print("ğŸ”§ [scripts] å·²è‡ªåŠ¨ä¿®å¤datasets LargeListå¯¼å…¥é—®é¢˜")
            except ImportError:
                # åˆ›å»ºåŸºç¡€å…¼å®¹ç±»
                class LargeList:
                    pass
                datasets.LargeList = LargeList
                print("ğŸ”§ [scripts] å·²åˆ›å»ºdatasets LargeListå…¼å®¹ç±»")

        # ä¿®å¤_FEATURE_TYPES
        from datasets.features import features
        if not hasattr(features, '_FEATURE_TYPES'):
            print("ğŸ”§ [scripts] _FEATURE_TYPESä¸å­˜åœ¨ï¼Œå¼€å§‹ä¿®å¤...")

            # åˆ›å»ºæ‰€æœ‰featureç±»å‹çš„å­—å…¸
            _FEATURE_TYPES = {}
            for attr_name in dir(features):
                attr = getattr(features, attr_name)
                if (hasattr(attr, '__name__') and
                    hasattr(attr, '__module__') and
                    attr.__module__ == 'datasets.features.features' and
                    (attr_name.endswith('Type') or 'Array' in attr_name or 'Value' in attr_name or 'Class' in attr_name)):
                    _FEATURE_TYPES[attr_name] = attr

            # æ‰‹åŠ¨æ·»åŠ ä¸€äº›é‡è¦çš„ç±»å‹
            if hasattr(features, 'Sequence'):
                _FEATURE_TYPES['LargeList'] = features.Sequence

            # å°†å…¶æ·»åŠ åˆ°featuresæ¨¡å—
            features._FEATURE_TYPES = _FEATURE_TYPES
            print(f"ğŸ”§ [scripts] å·²åˆ›å»º_FEATURE_TYPES ({len(_FEATURE_TYPES)}ä¸ªç±»å‹)")

    except ImportError:
        pass

# è¿è¡Œä¿®å¤
fix_datasets_import()

from .data_processor import download_dataset_files, analyze_dataset
from .model_trainer import run_training, run_inference
from .evaluate import main as evaluate_main
from .utils import clean_prediction_output, calculate_text_similarity

__version__ = "1.0.0"
__all__ = [
    'download_dataset_files',
    'analyze_dataset',
    'run_training',
    'run_inference',
    'evaluate_main',
    'clean_prediction_output',
    'calculate_text_similarity'
]
