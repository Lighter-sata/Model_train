#!/usr/bin/env python3
"""
é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - ä¸€é”®éƒ¨ç½²è„šæœ¬
è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒï¼Œå®‰è£…ä¾èµ–ï¼Œæ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
"""

import os
import sys
import json
import subprocess
import platform
from pathlib import Path

def print_banner():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("=" * 70)
    print("ğŸ° é‡‘èæ–‡æœ¬ç›¸ä¼¼åº¦åˆ†ç±»ç«èµ› - ä¸€é”®éƒ¨ç½²å·¥å…·")
    print("=" * 70)
    print("ğŸ“Š ç›®æ ‡: å°†åŸºçº¿å‡†ç¡®ç‡ 0.764 æå‡è‡³ 0.85+")
    print("ğŸ¯ é¢„æœŸ: 90åˆ†é’Ÿå†…å®Œæˆè®­ç»ƒï¼Œå‰30å")
    print("=" * 70)

def detect_platform():
    """æ£€æµ‹è¿è¡Œå¹³å°"""
    if os.path.exists('/mnt/workspace'):
        return 'modelscope'
    elif platform.system() == 'Linux':
        return 'linux'
    elif platform.system() == 'Darwin':
        return 'macos'
    elif platform.system() == 'Windows':
        return 'windows'
    else:
        return 'unknown'

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    print("\nğŸ” æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    version_str = f"{python_version.major}.{python_version.minor}.{python_version.micro}"
    print(f"  Pythonç‰ˆæœ¬: {version_str}")

    if python_version < (3, 8):
        print("âŒ éœ€è¦ Python 3.8+")
        return False
    elif python_version < (3, 10):
        print("âš ï¸  æ¨èä½¿ç”¨ Python 3.10+ ä»¥è·å¾—æœ€ä½³æ€§èƒ½")
    else:
        print("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚")

    # æ£€æŸ¥å†…å­˜ï¼ˆç®€å•æ£€æŸ¥ï¼‰
    try:
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
        print(f"  ç³»ç»Ÿå†…å­˜: {memory_gb:.1f} GB")
        if memory_gb < 16:
            print("âš ï¸  ç³»ç»Ÿå†…å­˜è¾ƒå°ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ€§èƒ½")
        else:
            print("âœ… ç³»ç»Ÿå†…å­˜å……è¶³")
    except ImportError:
        print("  å†…å­˜æ£€æŸ¥: è·³è¿‡ï¼ˆæœªå®‰è£…psutilï¼‰")

    return True

def check_gpu():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    print("\nğŸ® æ£€æŸ¥GPU...")
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
            print(f"âœ… GPUå¯ç”¨: {gpu_count}ä¸ªè®¾å¤‡")
            print(f"  è®¾å¤‡åç§°: {gpu_name}")

            # æ£€æŸ¥GPUå†…å­˜
            if gpu_count > 0:
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                print(f"  GPUå†…å­˜: {gpu_memory:.1f} GB")
                if gpu_memory < 8:
                    print("âš ï¸  GPUå†…å­˜è¾ƒå°ï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°çš„batch_size")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆéå¸¸æ…¢ï¼‰")
            return False
    except ImportError:
        print("âŒ æ— æ³•æ£€æŸ¥GPUï¼ˆtorchæœªå®‰è£…ï¼‰")
        return False

    return True

def install_dependencies():
    """å®‰è£…ä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…ä¾èµ–...")

    platform_name = detect_platform()

    try:
        if platform_name == 'modelscope':
            print("  æ£€æµ‹åˆ°é­”æ­å¹³å°ï¼Œä½¿ç”¨ä¸“ç”¨å®‰è£…è„šæœ¬...")
            result = subprocess.run([sys.executable, 'fix_modelscope_deps.py'],
                                  capture_output=True, text=True, check=True)
        else:
            print("  ä½¿ç”¨æ ‡å‡†å®‰è£…è„šæœ¬...")
            result = subprocess.run([sys.executable, 'install_deps.py'],
                                  capture_output=True, text=True, check=True)

        print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
        return True

    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e.stderr}")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•å¿«é€Ÿä¿®å¤
        print("\nğŸ”§ å°è¯•å¤‡ç”¨ä¿®å¤æ–¹æ¡ˆ...")
        try:
            print("  è¿è¡Œå¿«é€Ÿå…¼å®¹æ€§è¡¥ä¸...")
            result = subprocess.run([sys.executable, 'quick_pyarrow_fix.py'],
                                  capture_output=True, text=True, check=True)
            print("âœ… å…¼å®¹æ€§è¡¥ä¸åº”ç”¨æˆåŠŸ")

            # é‡æ–°å°è¯•å®‰è£…ä¾èµ–
            if platform_name == 'modelscope':
                result = subprocess.run([sys.executable, 'fix_modelscope_deps.py'],
                                      capture_output=True, text=True, check=True)
            else:
                result = subprocess.run([sys.executable, 'install_deps.py'],
                                      capture_output=True, text=True, check=True)

            print("âœ… ä¾èµ–å®‰è£…å®Œæˆï¼ˆä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰")
            return True

        except subprocess.CalledProcessError as e2:
            print(f"âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2.stderr}")
            return False

def run_setup_verification():
    """è¿è¡Œç¯å¢ƒéªŒè¯"""
    print("\nğŸ” éªŒè¯å®‰è£…...")
    try:
        result = subprocess.run([sys.executable, 'test_setup.py'],
                              capture_output=True, text=True, check=True)
        print("âœ… ç¯å¢ƒéªŒè¯é€šè¿‡")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ç¯å¢ƒéªŒè¯å¤±è´¥: {e.stderr}")
        return False

def run_full_pipeline():
    """è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
    print("\nğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒæµç¨‹...")
    print("é¢„è®¡è€—æ—¶: 90åˆ†é’Ÿ")
    print("-" * 50)

    try:
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        result = subprocess.run([sys.executable, 'main.py', '--step', 'all'],
                              check=True)
        print("\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
        return True

    except subprocess.CalledProcessError as e:
        print(f"\nâŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
        return False

def show_results():
    """æ˜¾ç¤ºç»“æœ"""
    print("\nğŸ“Š è®­ç»ƒç»“æœ:")

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_dir = Path("models")
    if model_dir.exists() and any(model_dir.rglob("*")):
        print("âœ… æ¨¡å‹æ–‡ä»¶å·²ç”Ÿæˆ")
        model_files = list(model_dir.rglob("*"))
        print(f"  æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    else:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

    # æ£€æŸ¥ç»“æœæ–‡ä»¶
    result_file = Path("results/enhanced_result.jsonl")
    if result_file.exists():
        print("âœ… é¢„æµ‹ç»“æœå·²ç”Ÿæˆ")
        print(f"  ç»“æœæ–‡ä»¶: {result_file}")
    else:
        print("âŒ æœªæ‰¾åˆ°é¢„æµ‹ç»“æœæ–‡ä»¶")

    # æ£€æŸ¥è¯„ä¼°æŠ¥å‘Š
    eval_dir = Path("results/evaluation_results")
    if eval_dir.exists():
        print("âœ… è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ")
        eval_files = list(eval_dir.glob("*"))
        if eval_files:
            print(f"  è¯„ä¼°æ–‡ä»¶: {len(eval_files)} ä¸ª")
    else:
        print("âŒ æœªæ‰¾åˆ°è¯„ä¼°æŠ¥å‘Š")

def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    print("\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. æ£€æŸ¥è®­ç»ƒç»“æœ: æŸ¥çœ‹ results/evaluation_results/ ç›®å½•")
    print("2. å‡†å¤‡ç«èµ›æäº¤:")
    print("   cp results/enhanced_result.jsonl results/result.json")
    print("3. æäº¤ result.json åˆ°ç«èµ›é¡µé¢")
    print("\nğŸ“ˆ æ€§èƒ½ç›®æ ‡:")
    print("- å‡†ç¡®ç‡: 0.85+ (ç›®æ ‡å‰30å)")
    print("- è®­ç»ƒæ—¶é—´: ~90åˆ†é’Ÿ")
    print("- GPUå†…å­˜: 8GB+ æ¨è")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()

    # æ­¥éª¤è®¡æ•°å™¨
    step = 1
    total_steps = 6

    # 1. ç³»ç»Ÿè¦æ±‚æ£€æŸ¥
    print(f"\n[{step}/{total_steps}] ç³»ç»Ÿè¦æ±‚æ£€æŸ¥")
    if not check_system_requirements():
        print("âŒ ç³»ç»Ÿä¸ç¬¦åˆè¦æ±‚ï¼Œè¯·å‡çº§ç³»ç»Ÿé…ç½®")
        return
    step += 1

    # 2. GPUæ£€æŸ¥
    print(f"\n[{step}/{total_steps}] GPUå¯ç”¨æ€§æ£€æŸ¥")
    gpu_available = check_gpu()
    if not gpu_available:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒå°†éå¸¸æ…¢")
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            return
    step += 1

    # 3. ä¾èµ–å®‰è£…
    print(f"\n[{step}/{total_steps}] ä¾èµ–å®‰è£…")
    if not install_dependencies():
        print("âŒ ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è§£å†³ä¾èµ–é—®é¢˜")
        return
    step += 1

    # 4. ç¯å¢ƒéªŒè¯
    print(f"\n[{step}/{total_steps}] ç¯å¢ƒéªŒè¯")
    if not run_setup_verification():
        print("âŒ ç¯å¢ƒéªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
        return
    step += 1

    # 5. æ‰§è¡Œè®­ç»ƒ
    print(f"\n[{step}/{total_steps}] æ‰§è¡Œè®­ç»ƒæµç¨‹")
    if not run_full_pipeline():
        print("âŒ è®­ç»ƒæµç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶")
        return
    step += 1

    # 6. æ˜¾ç¤ºç»“æœ
    print(f"\n[{step}/{total_steps}] æ˜¾ç¤ºç»“æœ")
    show_results()
    show_next_steps()

    print("\n" + "="*70)
    print("ğŸ‰ ä¸€é”®éƒ¨ç½²å®Œæˆï¼ç¥ç«èµ›é¡ºåˆ©ï¼")
    print("="*70)

if __name__ == '__main__':
    main()
